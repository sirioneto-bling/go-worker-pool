[![Continuous Integration Status](https://github.com/sirioneto-bling/go-worker-pool/actions/workflows/ci.yml/badge.svg)](https://github.com/sirioneto-bling/go-worker-pool/actions/workflows/ci.yml)

# go-worker-pool

Este projeto implementa um **Worker Pool** em Go: uma t√©cnica eficiente para gerenciar m√∫ltiplas goroutines executando tarefas concorrentes de forma controlada.

## üéØ Objetivo

Fornecer uma estrutura reutiliz√°vel e robusta para:

- Executar tarefas em paralelo.
- Processar resultados com tratamento de erro.
- Encerramento controlado (graceful shutdown) do worker pool.
- Aplicar em cen√°rios variados (requisi√ß√µes massivas via API, consumidores Kafka, etc).

## ‚úÖ Funcionalidades

- **Concorr√™ncia segura** com goroutines e canais.
- **Workers configur√°veis**: n√∫mero de workers e tamanho do canal de tarefas.
- **Adi√ß√£o de tarefas com ou sem retorno de resultado**.
- **Tratamento de erros personalizado** por tarefa.
- **Canal de resultados** para processar sa√≠das das tarefas.
- **Encerramento controlado**: aguarda o fim do processamento antes de liberar recursos.

## üîß Como usar

### 1. Criar o pool

```go
pool, err := work.NewPool(numWorkers, bufferSize)
```

### 2. Definir a tarefa

```go
job := work.NewJobWithResult(func() (any, error) {
    // l√≥gica da tarefa
}, func(err error) {
    // tratamento de erro
})
```

### 3. Adicionar tarefas

```go
pool.Start(ctx)
for i := 0; i < 100; i++ {
    pool.AddJob(job)
}
```

### 4. Aguardar o fim e consumir resultados

```go
go func() {
    pool.WaitJobs()
    pool.Stop()
}()

for result := range pool.Result() {
    if result.Error != nil {
        // lidar com erro
    } else {
        // lidar com sucesso
    }
}
```

---

## üí° Exemplo completo (main.go)

```go
package main

import (
	"context"
	"fmt"
	"log"
	"net/http"
	"time"

	"github.com/sirioneto-bling/go-tour/work"
)

func main() {
	start := time.Now()

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	pool, err := work.NewPool(100, 200)
	if err != nil {
		log.Fatal(err)
	}

	logger := log.Default()
	job := work.NewJobWithResult(sendRequestWithResult, handleRequestError)

	pool.Start(ctx)

	// Envia 500 tarefas
	for i := 0; i < 500; i++ {
		pool.AddJob(job)
	}

	// Aguarda processamento completo e encerra o pool
	go func() {
		pool.WaitJobs()
		logger.Println("Finalizando pool ap√≥s o processamento")
		pool.Stop()
	}()

	total, withError := 0, 0

	// Loop principal: aguarda conclus√£o ou cancelamento
	for {
		select {
		case <-ctx.Done():
			return
		case <-pool.Done():
			logger.Println("Total de tarefas processadas:", total)
			logger.Println("Com sucesso:", total-withError)
			logger.Println("Com erro:", withError)
			logger.Printf("Tempo de execu√ß√£o: %.2f segundos\n", time.Since(start).Seconds())
			return
		default:
			// Consome resultados
			for {
				result, ok := <-pool.Result()
				if !ok {
					break
				}

				total++
				if result.Error != nil {
					withError++
					logger.Println("[ERRO]", result.Error.Error())
				} else {
					logger.Println("[SUCESSO]", result.Value)
				}
			}
		}
	}
}

func sendRequestWithResult() (any, error) {
	const url = "https://www.google.com/"
	time.Sleep(2 * time.Second) // simula carga de trabalho
	res, err := http.Get(url)
	if err != nil {
		return nil, err
	}
	return fmt.Sprintf("%s retornou status %d", url, res.StatusCode), nil
}

func handleRequestError(err error) {
	log.Println("Erro durante requisi√ß√£o:", err)
}
```

---

## üß™ Benchmark

Para rodar os testes de benchmark, execute:

```bash
go test -bench=. ./tests
```

---

## üßµ Aplica√ß√µes

- **APIs**: disparar m√∫ltiplos processos em paralelo em uma √∫nica requisi√ß√£o (ex: uploads, c√°lculos, etc).
- **Consumidores Kafka**: manter workers processando eventos recebidos continuamente.
- **ETL / Data pipelines**: paralelizar transforma√ß√µes e envio de dados.
